<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author"      content="Sergey Pozhilov (GetTemplate.com)">
	
	<title>Alina Roitberg - Personal Webpage</title>

	<link rel="shortcut icon" href="assets/images/gt_favicon.png">
	
	<!-- Bootstrap -->
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	<!-- Icons -->
	<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
	<!-- Fonts -->
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	<!-- Custom styles -->
	<link rel="stylesheet" href="assets/css/styles.css">
	 <style>
	 
        /* Style for the horizontal bar */
        hr {
            border: none; /* Remove default border */
            height: 1px; /* Set the height of the bar */
            background-color: #bbc5c2; /* Set the background color of the bar */
            margin: 0px 0; /* Add some spacing above and below the bar */
			 width: 100%;
        }
    </style>

	<!--[if lt IE 9]> <script src="assets/js/html5shiv.js"></script> <![endif]-->
</head>
<body class="home">

<header id="header">
	<div id="head" class="parallax" parallax-speed="2">
		<h1 id="logo" class="text-center">
			<img class="img-circle" src="assets/images/alina.jpeg" alt="">
			<span class="title">Alina Roitberg</span>
			<span class="tagline">Full Professor of Machine Learning at the University of Hildesheim<br> 
				<a href="">roitberg [at] uni-hildesheim.de</a></span>
		</h1>
	</div>
	<hr>
<nav class="navbar navbar-default navbar-sticky">
    <div class="container-fluid">

        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"> 
                <span class="sr-only">Toggle navigation</span> 
                <span class="icon-bar"></span> 
                <span class="icon-bar"></span> 
                <span class="icon-bar"></span> 
            </button>
        </div>

        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav">
               <li><a href="index.html"><b>Home</b></a></li>
                <li class="active"><a href="publications.html"><b>Publications</b></a></li>
                <!--<li><a href="teaching.html"><b>Teaching</b></a></li>-->
                <!-- Deactivated per request: Theses/Jobs -->
                <!-- <li><a href="teaching.html"><b>Theses</b></a></li> -->
                <!--<li><a href="group.html"><b>Group</b></a></li>-->
                <!-- <li><a href="applications.html"><b>Applications / Jobs</b></a></li> -->
            </ul>
        </div>

    </div>
</nav>
</header>

<main id="main">

	<div class="container">
		
		
		
	
		

		<div class="row section clients topspace">
			<h2 class="section-title"><span>Publications</span></h2>
			<div class="col-lg-12">
				<p> For a complete and up-to-date publication list, check my <a href="https://scholar.google.com/citations?user=UuEFRDoAAAAJ&hl=en&oi=ao">Google Scholar profile</a>.<p>
				
				
<ul>
<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2024</div>

<li><strong>Advancing Open-Set Domain Generalization Using Evidential Bi-Level Hardest Domain Scheduler.</strong> K. Peng, D. Wen, K. Yang, A. Luo, Y. Chen, J. Fu, M. S. Sarfraz, A. Roitberg, R. Stiefelhagen. <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2024 (accepted). [<a href="https://arxiv.org/pdf/2409.17555">pdf</a>] [<a href="https://github.com/KPeng9510/EBiL-HaDS">code</a>]</li>
<li><strong>Referring Atomic Video Action Recognition.</strong> K. Peng, J. Fu, K. Yang, D. Wen, Y. Chen, R. Liu, J. Zheng, J. Zhang, M.S. Sarfraz, R. Stiefelhagen, A. Roitberg. <em>European Conference on Computer Vision (ECCV)</em>, Milan, Italy, 2024 (accepted). [<a href="https://arxiv.org/pdf/2407.01872">pdf</a>] [<a href="https://github.com/KPeng9510/RAVAR">data+code</a>]</li>
<li><strong>Skeleton-Based Human Action Recognition with Noisy Labels.</strong> Y. Xu, K. Peng, D. Wen, R. Liu, J. Zheng, Y. Chen, J. Zhang, A. Roitberg, K. Yang, R. Stiefelhagen. <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2024 (accepted). [<a href="https://arxiv.org/pdf/2403.09975">pdf</a>] [<a href="https://github.com/xuyizdby/NoiseEraSAR">code</a>]</li>
<li><strong>SynthAct: Towards Generalizable Human Action Recognition based on Synthetic Data.</strong> D. Schneider, M. Keller, Z. Zhong, K. Peng, A. Roitberg, J. Beyerer, R. Stiefelhagen. <em>IEEE International Conference onRobotics and Automation (ICRA)</em>, Yokohama, Japan, May 2024.</li>
<li><strong>Chart4blind: An intelligent interface for chart accessibility conversion.</strong> O. Moured, M. Baumgarten-Egemole, K. Müller, A. Roitberg, T. Schwarz, R. Stiefelhagen. <em>Proceedings of the 29th International Conference on Intelligent User Interfaces</em>, March 2024, pp. 504-514.</li>
<li><strong>TransKD: Transformer Knowledge Distillation for Efficient Semantic Segmentation.</strong> R. Liu, K. Yang, A. Roitberg, J. Zhang, K. Peng, H. Liu, Y. Wang, R. Stiefelhagen. <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2024. [<a href="https://arxiv.org/pdf/2202.13393">pdf</a>] [<a href="https://github.com/RuipingL/TransKD">code</a>]</li>
<li><strong>Bildbasierte Baufortschrittsüberwachung.</strong> M. Koulakis, A. Albrecht, M. Wagner, A. Richter, F. Andres, A. Roitberg, J. Petereit, R. Stiefelhagen. <em>Künstliche Intelligenz im Bauwesen: Grundlagen und Anwendungsfälle</em>, May 10, 2024, pp. 205-219. Wiesbaden: Springer Fachmedien Wiesbaden. <strong>(book chapter)</strong> [<a href="https://doi.org/10.1007/978-3-658-42796-2_12">DOI</a>]</li>
<li><strong>Navigating Open Set Scenarios for Skeleton-based Action Recognition.</strong> K. Peng, C. Yin, J. Zheng, R. Liu, D. Schneider, J. Zhang, K. Yang, M.S. Sarfraz, R. Stiefelhagen, A. Roitberg. <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, Vancouver, Canada, February 2024. [<a href="https://arxiv.org/pdf/2312.06330.pdf">pdf</a>] [<a href="https://github.com/KPeng9510/OS-SAR" target="_blank">data+code</a>]</li>

<li><strong>Elevating Skeleton-based Action Recognition with Efficient Multi-modality Self-supervision.</strong> Y. Wei, K. Peng, A. Roitberg, J. Zhang, J. Zheng, R. Liu, Y. Chen, K. Yang, R. Stiefelhagen. <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Seoul, Korea, April 2024. [<a href="https://arxiv.org/pdf/2309.12009.pdf">pdf</a>] [<a href="https://github.com/desehuileng0o0/IKEM" target="_blank">code</a>]</li>

<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2023</div>
<li><strong>Quantized Distillation: Optimizing Driver Activity Recognition Models for Resource-Constrained Environments.</strong> Calvin Tanama, Kunyu Peng, Zdravko Marinov, Rainer Stiefelhagen, Alina Roitberg. <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2023.  [<a href="https://arxiv.org/abs/2311.05970">pdf</a>] [<a href="https://github.com/calvintanama/qd-driver-activity-reco" target="_blank">code</a>]</li>

<li><strong>Delving Deep into One-Shot Skeleton-based Action Recognition with Diverse Occlusions.</strong> Kunyu Peng, Alina Roitberg, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen. <em>IEEE Transactions on Multimedia (TMM)</em>, 2023 [<a href="https://arxiv.org/pdf/2202.11423.pdf">pdf</a>] [<a href="https://github.com/KPeng9510/Trans4SOAR" target="_blank">code</a>].</li>

<li><strong>Line Graphics Digitization: A Step Towards Full Automation.</strong> Omar Moured, Jiaming Zhang, Alina Roitberg, Thorsten Schwarz, Rainer Stiefelhagen. <em>International Conference on Document Analysis and Recognition</em>. Cham: Springer Nature Switzerland, 2023. [<a href="https://arxiv.org/pdf/2307.02065.pdf">pdf</a>] [<a href="https://github.com/moured/Document-Graphics-Digitization.git" target="_blank">code</a>]</li>


<li><strong>Towards Privacy-Supporting Fall Detection via Deep Unsupervised RGB2Depth Adaptation.</strong> Hejun Xiao, Kunyu Peng, Xiangsheng Huang, Alina Roitberg, Hao Li, Zhaohui Wang, Rainer Stiefelhagen. <em>IEEE Sensors Journal</em>, 2023. [<a href="https://arxiv.org/pdf/2308.12049.pdf">pdf</a>] [<a href="https://github.com/1015206533/privacy_supporting_fall_detection" target="_blank">code</a>]</li>



<li><strong>On Transferability of Driver Observation Models from Simulated to Real Environments in Autonomous Cars.</strong> Walter Morales-Alvarez*, Novel Certad*, Alina Roitberg*, Rainer Stiefelhagen, Cristina Olaverri-Monreal. <em>IEEE Conference on Intelligent Transportation Systems (ITSC)</em>, 2023. [<a href="https://arxiv.org/pdf/2307.16543.pdf">pdf</a>]</li>



	<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2022</div>
<li><strong>Multimodal Generation of Novel Action Appearances for Synthetic-to-Real Recognition of Daily Living Activities.</strong> Zdravko Marinov*, Alina Roitberg*, David Schneider*, Rainer Stiefelhagen. <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2022 [<a href="https://arxiv.org/pdf/2208.01910.pdf">pdf</a>].</li>
	
<li><strong>TransDARC: Transformer-based Driver Activity Recognition with Latent Space Feature Calibration.</strong> Kunyu Peng, Alina Roitberg, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen. <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2022 [<a href="https://arxiv.org/pdf/2203.00927.pdf">pdf</a>] [<a href="https://github.com/KPeng9510/TransDARC" target="_blank">code</a>].</li>
	
	

<li><strong>Multi-modal Depression Estimation based on Sub-attentional Fusion.</strong> Ping-Cheng Wei, Kunyu Peng, Alina Roitberg, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen. <em>International Workshop on Assistive Computer Vision and Robotics (ACVR) with European Conference on Computer Vision (ECCV)</em>, Springer, 2022.</li>


	<li><strong>Is my Model Overconfident? Uncertainty-aware Driver Observation with Reliable and Interpretable Confidence Estimates.</strong> Alina Roitberg, Kunyu Peng, David Schneider, Marios Koulakis, Kailun Yang, Manuel Martinez, Rainer Stiefelhagen. <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2022  [<a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/TransITS_CARING_ReliableDriverObservation.pdf">pdf</a>].</li>
	
<li><strong>Pose-based Contrastive Learning for Domain Agnostic Activity Representations.</strong> David Schneider, Saqiub Sarfraz, Alina Roitberg, Rainer Stiefelhagen. <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022.</li>

	<li><strong>Should I take a walk? Estimating Energy Expenditure from Video Data. </strong>Kunyu Peng*, Alina Roitberg*, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen. <em>CVPR Workshop on Computer Vision for Physiological Measurement</em>, IEEE, June 2022  [<a href="https://arxiv.org/pdf/2202.00712" target="_blank">pdf</a>] [<a href="https://github.com/KPeng9510/Vid2Burn" target="_blank">code</a>].</li>
	<li><strong>MASS: Multi-Attentional Semantic Segmentation of LiDAR Data for Dense Top-View Understanding.</strong> K. Peng, J. Fei, K. Yang, A. Roitberg, J. Zhang, F. Bieder, P. Heidenreich, C. Stiller, R. Stiefelhagen. <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2022 <a href="https://arxiv.org/pdf/2107.00346.pdf" target="_blank">[pdf]</a> <a href="https://github.com/KPeng9510/MASS" target="_blank">[code]</a></li>
	<li><strong>Transfer beyond the Field of View: Dense Panoramic Semantic Segmentation via Unsupervised Domain Adaptation.</strong> Jiaming Zhang, Chaoxiang Ma, Kailun Yang, Alina Roitberg, Kunyu Peng, Rainer Stiefelhagen. <em> IEEE Transactions on Intelligent Transportation Systems</em>, 2022<strong> </strong>[<a href="https://arxiv.org/pdf/2110.11062.pdf" target="_blank">pdf</a>] [<a href="https://github.com/chma1024/DensePASS" target="_blank">data</a>]</li>
	
	<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2021</div>


	<li><strong>Affect-DML: Context-Aware One-Shot Recognition of Human Affect using Deep Metric Learning.</strong> Kunyu Peng, Alina Roitberg, David Schneider, Marios Koulakis, Kailun Yang, Rainer Stiefelhagen. <em>International Conference on Automatic Face and Gesture Recognition</em>, IEEE, December 2021.</li>
	<li><strong>Let's Play for Action: Recognizing Activities of Daily Living by Learning from Life Simulation Video Games. </strong>Alina Roitberg*, David Schneider*, Aulia Djamal, Constantin Seibold, Simon Reiß, Rainer Stiefelhagen. In <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, Prague, Czech Republic, September 2021 [<a href="https://arxiv.org/pdf/2107.05617.pdf" target="_blank">pdf</a>] [<a href="https://github.com/aroitberg/sims4action" target="_blank">website</a>]</li>
	<li><strong>From Driver Talk To Future Action: Vehicle Maneuver Prediction by Learning from Driving Exam Dialogs.</strong> Alina Roitberg, Simon Reiß, Rainer Stiefelhagen. <em>IEEE Intelligent Vehicles Symposium</em>, Nagoya, Japan (virtual), July 2021 [<a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/Roitberg_IV2021_DriverTalk.pdf">pdf</a>]</li>
	<li><strong>DensePASS: Dense Panoramic Semantic Segmentation via Unsupervised Domain Adaptation with Attention-Augmented Context Exchange.</strong> Chaoxiang Ma, Jiaming Zhang, Kailun Yang, Alina Roitberg, Kunyu Peng, Rainer Stiefelhagen. <em>IEEE International Conference on Intelligent Transportation Systems (ITSC)</em>, 2021 [<a href="https://arxiv.org/pdf/2108.06383.pdf" target="_blank">pdf</a>] [<a href="https://github.com/chma1024/DensePASS" target="_blank">website</a>]</li>
	<li><strong>Uncertainty-aware Models for Deep Learning-based Human Activity Recognition and Applications in Intelligent Vehicles.</strong> Alina Roitberg. PhD Dissertation, April 2021 [<a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/Dissertation_Roitberg_UncertaintyAwareDriverActivityRecognition.pdf">pdf</a>]</li>
	<li><strong>Uncertainty-sensitive Activity Recognition: a Reliability Benchmark and the CARING Models. </strong>Alina Roitberg, Monica Haurilet, Manuel Martinez and Rainer Stiefelhagen.<em> </em><span class="st"><em>International Conference on Pattern Recognition (ICPR)</em>,</span>&nbsp; IEEE, January 2021, oral (&lt;10% acceptance rate for orals). [<strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/UncertaintyCARINGActionRecognition_ICPR2021.pdf">pdf</a></strong>]</li>
	<li><strong>Multi-Task Learning for Calorie Prediction on a Novel Large-Scale Recipe Dataset Enriched with Nutritional Information.&nbsp;</strong>Robin Ruede, Verena Heusser, Lukas Frank, Alina Roitberg, Monica Haurilet, Rainer Stiefelhagen. <span class="st"><em>International Conference on Pattern Recognition (ICPR)</em>,</span>&nbsp; IEEE, January 2021. [<a href="https://arxiv.org/pdf/2011.01082.pdf" target="_blank">pdf</a>] [<a href="https://www.newscientist.com/article/2260415-computer-vision-can-estimate-calorie-content-of-food-at-a-glance/" target="_blank">press article</a>]</li>
	<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2020</div>

	<li><span dir="ltr" id="divtagdefaultwrapper"><strong>Personalisation and Control Transition Between Automation and Driver in Highly Automated Cars.</strong> M. Flad, P. Karg, P, A. Roitberg, M. Martin, M. Mazewitsch, C. Lange, E. Kenar, L. Ahrens, B. Flecken, L. Kalb, B. Karakaya, J. Ludwig, A. Pruksch, R. Stiefelhagen, S. Hohmann. <em>Smart Automotive Mobility. Human–Computer Interaction Series. Springer (<strong>book chapter</strong>), </em>2020 [<a href="https://doi.org/10.1007/978-3-030-45131-8_1" target="_blank">doi</a>]<em></em></span></li>
	<li><strong>Open Set Driver Activity Recognition. </strong>Alina Roitberg, Chaoxiang Ma, Monica Haurilet and Rainer Stiefelhagen. <em>Intelligent Vehicles Symposium (IV),</em>&nbsp; IEEE, October 2020, <strong>Best Student Paper 2nd Place Award</strong>. [<strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/OpenSetDriverActivityRecognition_IV2020.pdf">pdf</a></strong>]</li>
	<li><strong>Deep Classification-driven Domain Adaptation for Cross-Modal Driver Behavior Recognition. </strong>Simon Reiß*, Alina Roitberg*, Monica Haurilet, and Rainer Stiefelhagen. <em>Intelligent Vehicles Symposium (IV),</em>&nbsp; IEEE, October 2020. [<strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/CrossDomainDriverActivityRecognition_IV2020.pdf">pdf</a></strong>]</li>
	<li><strong>CNN-based Driver Activity Recognition: Shedding Light on Deep Spatiotemporal Representations. </strong>Alina Roitberg, Monica Haurilet, Simon Reiß and Rainer Stiefelhagen. <em>International Conference on Intelligent Transportation Systems (ITSC)</em><em>,</em>&nbsp; IEEE, September 2020. [<strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/InterpretableCNNsDriverObservation_ITSC2020.pdf">pdf</a></strong>]</li>
	<li><strong>Activity-aware Attributes for Zero-Shot Driver Behavior Recognition. </strong>Simon Reiß*, Alina Roitberg*, Monica Haurilet, and Rainer Stiefelhagen.<em> In CVPR Workshop on Visual Learning with Limited Labels (VL-LL)</em>. IEEE, June 2020. [<strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/AttributesZeroShotDriverActivity_CVPRW2020.pdf">pdf</a></strong>]</li>
	
	<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2019</div>

	<li><strong>Drive&amp;Act: A Multi-modal Dataset for Fine-grained Driver Behavior Recognition in Autonomous Vehicles. </strong>Manuel Martin*, Alina Roitberg*, Monica Haurilet, Matthias Horne, Simon Reiß, Michael Voit, Rainer Stiefelhagen. In<strong><em> </em></strong><em>International Conference on Computer Vision (<a href="http://iccv2019.thecvf.com/" target="_blank">ICCV</a>), IEEE, Seoul, South Korea,</em> Oct. 2019 [<strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/DriveAndAct_ICCV2019.pdf">pdf]</a></strong> [<a href="http://cvhci.anthropomatik.kit.edu/~aroitberg/publications/DriveAndAct_ICCV2019.bib"><strong>bib</strong></a>] (25.0% acceptance rate, * denotes equal contribution)</li>
	<li><strong>WiSe - Slide Segmentation in the Wild. </strong>Monica Haurilet, Alina Roitberg, Manuel Martinez and Rainer Stiefelhagen.<em> In International Conference for Document Analysis and Recognition, (ICDAR), IEEE, Sydney, Australia, </em>Sep. 2019 <strong><a href="https://cvhci.anthropomatik.kit.edu/~mhaurile/papers/2019_ICDAR_WiSe.pdf">[pdf]</a> </strong></li>
	<li><strong>Learning Fine-Grained Image Representations for Mathematical Expression Recognition. </strong>Sidney Bender*, Monica Haurilet*, Alina Roitberg, Rainer Stiefelhagen, <em>ICDAR Workshop on Graphics Recognition<em>, Sydney, Australia, </em></em>Sep. 2019&nbsp;<strong><a href="https://cvhci.anthropomatik.kit.edu/~mhaurile/papers/2019_GREC_FGFE.pdf">[pdf]</a></strong><em> </em>(* denotes equal contribution)</li>
	<li><strong>End-to-end Prediction of Driver Intention using 3D Convolutional Neural Networks. </strong>Patrick Gebert*, Alina Roitberg*, Monica Haurilet and Rainer Stiefelhagen.<em> In </em><span class="st"><em> </em><em><em>In</em>telligent Vehicles Symposium (IV), IEEE, Paris, France, June </em>2019&nbsp;(* denotes equal contribution)</span></li>
	<li><strong data-bind="text: title">It’s not about the Journey; It’s about the Destination: Following Soft Paths under Question-Guidance for Visual Reasoning. </strong>Monica Haurilet, Alina Roitberg, Rainer Stiefelhagen.&nbsp;<em> In Conference on Computer Vision and Pattern Recognition (CVPR)</em>, <em>IEEE</em>, <em><span data-bind="text: city"></span>Long Beach,<span data-bind="text: country"> USA,</span> </em>June 2019 <strong><a href="https://cvhci.anthropomatik.kit.edu/~mhaurile/papers/CVPR2019_SoftPaths.pdf">[pdf]</a> </strong>(25.2% acceptance rate)</li>
	<li><strong>Analysis of Deep Fusion Strategies for Multi-modal Gesture Recognition. </strong>Alina Roitberg*, Tim Pollert*, Monica Haurilet, Manuel Martin, Rainer Stiefelhagen. <em>CVPR </em><em>Workshop on Analysis and Modeling of Faces and Gestures (AMFG)</em>, <em>IEEE</em>, <em><span data-bind="text: city"></span>Long Beach,<span data-bind="text: country"> USA, </span></em><span data-bind="text: country">June</span><em><span data-bind="text: country"> </span></em>2019 <strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/DeepFusionGestureRecognition_AMFG_CVPRW2019.pdf">[pdf]</a><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/roitbergCVPRW2019DeepFusion.bib">[bib]</a></strong>(* denotes equal contribution)<strong><em></em> </strong></li>
	
	<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2018</div>

	<li><strong><span data-bind="text: title">Informed Democracy: Voting-based Novelty Detection for Action Recognition.</span></strong><strong> </strong>Alina Roitberg, Ziad Al-Halah, Rainer Stiefelhagen.&nbsp;<em> In British Machine Vision Conference (BMVC)</em><em><span data-bind="text: city">, Newcastle upon Tyne</span>, <span data-bind="text: country">UK,</span> </em>2018 <strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/Roitberg2018a_BMVC_NoveltyDetection.pdf">[pdf]</a><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/Poster_Roitberg2018a_BMVC18_NoveltyDetection.pdf">[poster]</a><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/roitbergBMVC2018novelty.bib">[bib]</a></strong> <strong><em></em></strong>(29.5% acceptance rate)</li>
	<li><strong>Towards a Fair Evaluation of Zero-Shot Action Recognition using External Data<span data-bind="text: title">.</span> </strong>Alina Roitberg, Manuel Martinez, Monica Haurilet, Rainer Stiefelhagen.&nbsp;<em> In ECCV Workshop on&nbsp;Shortcomings in Vision and Language (SiVL),&nbsp;Springer, Munich, Germany<span data-bind="text: country">,</span> </em>2018 <strong><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/Roitberg2018b_SiVL_ECCVWorkshop_ZeroShotAction.pdf">[pdf]</a><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/Poster_Roitberg2018b_SiVL_ECCVWorkshop_ZeroShotAction.pdf">[poster]</a><a href="https://cvhci.anthropomatik.kit.edu/~aroitberg/publications/roitbergSiVL2018ZSAction.bib">[bib] </a><em>(spotlight presentation)</em></strong></li>
	<li><strong>Estimating Mental Load in Passive and Active Tasks from Pupil and Gaze Changes using Bayesian Surprise. </strong>Elena Wolf, Manuel Martinez, Alina Roitberg, Rainer Stiefelhagen and Barbara Deml. In <em>ACM</em> <em>ICMI Modeling Cognitive Processes from Multimodal Data Workshop (ICMI-MCPMD), Boulder, Colorado, USA, </em>2018</li>
	
	<div style="text-align: center; font-size: 2em; font-weight: bold; margin-top: 20px; margin-bottom: 20px;">2017 and prior</div>

	<li><strong>Using Technology Developed for Autonomous Cars to Help Navigate Blind People. </strong>Manuel Martinez, Alina Roitberg, Daniel Koester, Boris Schauerte, Rainer Stiefelhagen. <em>ICCV Workshop on Assistive Computer Vision and Robotics (ACVR)</em>, 2017</li>
	<li><strong>Connecting Artificial Brains to Robots in a Comprehensive Simulation Framework: The Neurorobotics Platform</strong>. Egidio Falotico, Lorenzo Vannucci, Alessandro Ambrosano, Ugo Albanese, Stefan Ulbrich, Juan Camilo Vasquez Tieck, Georg Hinkel, Jacques Kaiser, Igor Peric, Oliver Denninger, Nino Cauli, Murat Kirtay, Arne Roennau, Gudrun Klinker, Axel Von Arnim, Luc Guyot, Daniel Peppicelli, Pablo Martínez-Cañada, Eduardo Ros, Patrick Maier, Sandro Weber, Manuel Huber, David Plecher, Florian Röhrbein, Stefan Deser, Alina Roitberg, Patrick van der Smagt, Rüdiger Dillman, Paul Levi, Cecilia Laschi, Alois C Knoll, Marc-Oliver Gewaltig, <em>Frontiers in neurorobotics 11</em>, 2017</li>
	<li><strong>Improved skeleton estimation by means of depth data fusion from multiple depth cameras. </strong>Marco Carraro, Matteo Munaro, Alina Roitberg, Emanuele Menegatti.<em> In International Conference on Intelligent Autonomous Systems, Springer,</em> 2016</li>
	<li><strong>Multimodal human activity recognition for industrial manufacturing processes in robotic workcells. </strong>Alina Roitberg, Nikhil Somani, Alexander Perzylo, Markus Rickert, and Alois Knoll.<em> In ACM International Conference on Multimodal Interaction (ICMI)</em>, Seattle, USA, 2015</li>
	<li><strong>Human Activity Recognition in the Context of Industrial Human-Robot Interaction. </strong>Alina Roitberg, Alexander Perzylo, Nikhil Somani, Manuel Giuliani, Markus Rickert, and Alois Knoll. <em>In Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC 2014), IEEE,</em> Siem Reap, Cambodia, 2014</li>
</ul></div></div>

			</div>
		</div> <!-- /section -->

	</div>	<!-- /container -->

</main>






<!-- JavaScript libs are placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="assets/js/template.js"></script>
<script>
    $(document).ready(function(){
        $('.navbar-toggle').collapse();
    });
</script>
</body>
</html>
